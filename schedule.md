
# Schedule

Finish readings before the start of class  
Sign up to present here: [signups link](https://docs.google.com/spreadsheets/d/1lXe3n_sXpLf8oU1nzPsuDv_25Q_7sX5WypQtb_MqvSQ/edit?usp=sharing)

# Topics & Readings

## Week 0: Introduction
1: _Optional_ Capel & Brereton [What is Human-Centered about Human-Centered AI? A Map of the Research Landscape](https://dl.acm.org/doi/full/10.1145/3544548.3580959) CHI 2023    

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing)_    

## Week 1: Fairness and Bias

1: Martinez & Kirchner ["The secret bias hidden in mortgage-approval algorithms"](https://themarkup.org/denied/2021/08/25/the-secret-bias-hidden-in-mortgage-approval-algorithms) The Markup 2021   
2: Suresh & Guttag ["A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle"](https://dl.acm.org/doi/10.1145/3465416.3483305) EAAMO 2021   
3: Cheng et al. [Soliciting Stakeholders’ Fairness Notions in Child Maltreatment Predictive Systems](https://dl.acm.org/doi/abs/10.1145/3411764.3445308) CHI 2021   
4: Yang et al. [Fair Machine Guidance to Enhance Fair Decision Making in Biased People](https://dl.acm.org/doi/full/10.1145/3613904.3642627) CHI 2024   

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_    

## Week 2: Transparency and Explainability

1: Knight ["The Dark Secret at the Heart of AI"](https://www.technologyreview.com/2017/04/11/5113/the-dark-secret-at-the-heart-of-ai/) MIT Technology Review 2017  
2: Poursabzi-Sangdeh et al. [Manipulating and Measuring Model Interpretability](https://dl.acm.org/doi/10.1145/3411764.3445315) CHI 2021   
3: Ehsan et al. ["The Who in XAI: How AI Background Shapes Perceptions of AI
Explanations"](https://dl.acm.org/doi/full/10.1145/3613904.3642474) CHI 2024   
4: Kim et al. [""Help Me Help the AI": Understanding How Explainability Can
Support Human-AI Interaction"](https://dl.acm.org/doi/full/10.1145/3544548.3581001) CHI 2023  

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_     

## Week 3: Setting Expectations
1: Zhang et al. ["'An Ideal Human': Expectations of AI Teammates in Human-AI Teaming"](https://dl.acm.org/doi/10.1145/3432945) CSCW 2021   
2: Kloft et al. ["AI enhances our performance, I have no doubt this one will do the same": The Placebo Efect Is Robust to Negative Descriptions of AI](https://dl.acm.org/doi/full/10.1145/3613904.3642633) CHI 2024   
3: Kocielnik, Amershi & Bennett ["Will You Accept an Imperfect AI? Exploring Designs for Adjusting End-user Expectations of AI Systems"](https://www.microsoft.com/en-us/research/uploads/prod/2019/01/chi19_kocielnik_et_al.pdf) CHI 2019   
4: Badger ["How to Make Waiting for the Bus Feel Much, Much Shorter"](https://www.bloomberg.com/news/articles/2014-01-22/how-to-make-waiting-for-the-bus-feel-much-much-shorter) Bloomberg CityLab 2014


_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_    

## Week 4: Designing for Failure: Recourse and Contestability  
1: Matsakis ["What Does a Fair Algorithm Actually Look Like?"](https://www.wired.com/story/what-does-a-fair-algorithm-look-like/) Wired 2018   
2: Wang et al. ["GAM Coach: Towards Interactive and User-centered Algorithmic Recourse"](https://dl.acm.org/doi/full/10.1145/3544548.3580816) CHI 2023   
2: Lyons, Velloso & Miller ["Conceptualising Contestability: Perspectives on Contesting Algorithmic Decisions"](https://dl.acm.org/doi/abs/10.1145/3449180) CSCW 2021   
3: Kaminski & Urban ["The Right to Contest AI"](https://www.jstor.org/stable/27083420) Columbia Law Review 2021   

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_    

## Week 5: "The Algorithm"
1: Schechtman ["Life in the algorithm"](https://yalereview.org/article/anna-shechtman-algorithm-kyle-chayka-taylor-lorenz) Yale Review 2023   
2: DeVito, Gergle & Bernholtz ["'Algorithms ruin everything': #RIPTwitter, Folk Theories, and Resistance to Algorithmic Change in Social Media"](https://dl.acm.org/doi/abs/10.1145/3025453.3025659) CHI 2017    
3: Steen, Yurchenko & Klug ["You Can (Not) Say What You Want: Using Algospeak to Contest and Evade Algorithmic Content Moderation on TikTok](https://journals.sagepub.com/doi/full/10.1177/20563051231194586) Social Media + Society 2023    
4: Shen et al. [Everyday Algorithm Auditing: Understanding the Power of Everyday Users in Surfacing Harmful Algorithmic Behaviors](https://dl.acm.org/doi/abs/10.1145/3479577) CSCW 2021   


_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_      

## Week 6: Generative AI
1: **ONLY Sections 3 & 4** of Cetinic & She ["Understanding and Creating Art with AI: Review and Outlook"](https://dl.acm.org/doi/full/10.1145/3475799) ACM Transactions on Multimedia 2022   
2: Simonite [These Deepfake Voices Can Help Trans Gamers](https://www.wired.com/story/deepfake-voices-help-trans-gamers/) Wired 2021    
3: Weisz et al. ["Design Principles for Generative AI Applications"](https://dl.acm.org/doi/full/10.1145/3613904.3642466) CHI 2024    
4: Wadinambiarachchi et al. ["The Effects of Generative AI on Design Fixation and Divergent Thinking"](https://dl.acm.org/doi/full/10.1145/3613904.3642919) CHI 2024 

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_    


## Week 7: No Class

## Week 8: Ethics and Social Justice  
1: Abebe, Barocas, Kleinberg, Levy, Raghavan & Robinson ["Roles for Computing in Social Change"](https://arxiv.org/pdf/1912.04883.pdf) FAccT 2020   
2: Matthew Hutson ["Who Should Stop Unethical A.I.?"](https://www.newyorker.com/tech/annals-of-technology/who-should-stop-unethical-ai) The New Yorker 2021   
3: Capel & Brereton ["Don’t ask if artificial intelligence is good or fair, ask how it shifts power"](https://www.nature.com/articles/d41586-020-02003-2) Nature 2020        
4: Estrada [Human supremacy as posthuman risk](https://digitalcommons.odu.edu/sociotechnicalcritique/vol1/iss1/5/) The Journal of Sociotechnical Critique 2020    

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_    

## Week 9: Privacy/Security
1: Weinshel, Wei, Mondal, Choi, Shan, Dolin, Mazurek, & Ur ["Oh, the Places You've Been! User Reactions to Longitudinal Transparency About Third-Party Web Tracking and Inferencing"](https://dl.acm.org/doi/abs/10.1145/3319535.3363200) CCS 2019   
2: Shou ["The Next Big Privacy Hurdle? Teaching AI to Forget"](https://www.wired.com/story/the-next-big-privacy-hurdle-teaching-ai-to-forget/) Wired 2019      
3: Asthana et al. ["'I know even if you don’t tell me': Understanding Users’ Privacy Preferences Regarding AI-based Inferences of Sensitive Information for Personalization"](https://dl.acm.org/doi/full/10.1145/3613904.3642180) CHI 2024     
4: Lee et al. ["Deepfakes, Phrenology, Surveillance, and More! A Taxonomy of AI Privacy Risks"](https://dl.acm.org/doi/full/10.1145/3613904.3642116) CHI 2024    

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_    


## Week 10: Student Choice   
1: Rotman ["People are worried that AI will take everyone’s jobs. We’ve been here before."](https://www.technologyreview.com/2024/01/27/1087041/technological-unemployment-elon-musk-jobs-ai/) MIT Technology Review 2024        
2: Frey & Osborne ["Generative AI and the Future of Work: A Reappraisal"](https://heinonline.org/HOL/P?h=hein.journals/brownjwa30&i=161) Brown Journal of World Affairs 2023   
<!--- Berger ["SAG-AFTRA’s AI Deal: A $5 Billion Gamble On The Future Of Voice Acting"](https://www.forbes.com/sites/virginieberger/2024/08/21/sag-aftras-ai-deal-a-5-billion-gamble-on-the-future-of-voice-acting/) Forbes 2024 -->       
3: Ben Kirman et al. ["CHI and the Future Robot Enslavement of Humankind; A Retrospective"](https://dl.acm.org/doi/abs/10.1145/2468356.2468740) CHI Extended Abstracts 2013    
4: Brown & Greene ["The Future of Work is No Work: A Call to Action for Designers in the Abolition of Work"](https://dl.acm.org/doi/abs/10.1145/3491101.3516385) CHI Extended Abstracts 2022      

_Slides: [Overview Slides](https://drive.google.com/drive/folders/1ZITVvr1xZC3Y5t2y9AKT7SBIuqELwMVu?usp=sharing) [Student Slides](https://drive.google.com/drive/folders/1dCDxycqfbXKI5tYDmxAY2ZvtPCMKd1Zm?usp=sharing)_    
